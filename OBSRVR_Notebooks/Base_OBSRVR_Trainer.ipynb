{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11358456,"sourceType":"datasetVersion","datasetId":7108729}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers datasets accelerate torch tokenizers > /dev/null","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!git clone https://huggingface.co/  #Add username/model_name only if resuming training","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!ls t5-obsrvr/last-checkpoint/ # only if resuming training","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!ls /kaggle/input/obsrvr-data/","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from datasets import load_dataset\n\nBASE = \"/kaggle/input/obsrvr-data/\"\n\ndataset = load_dataset(\"json\", data_files={\"data\": BASE + \"data_file.json\"}) # here replace data_file with your file\n\ndataset = dataset[\"data\"].train_test_split(test_size=0.15) \n\ntrain_val_split = dataset[\"train\"].train_test_split(test_size=0.15)  \ndataset[\"train\"] = train_val_split[\"train\"]\ndataset[\"validation\"] = train_val_split[\"test\"]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import T5Tokenizer, T5ForConditionalGeneration\n\nmodel_name = \"t5-small\" # either t5-small or t5-base if new training else username/model_name\ntokenizer_name = \"t5-small\" # either t5-small or t5-base depending on model you chose\n\ntokenizer = T5Tokenizer.from_pretrained(tokenizer_name, cache_dir=None)\nmodel = T5ForConditionalGeneration.from_pretrained(model_name, cache_dir=None)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def preprocess_function(examples):\n\n    inputs = [ex for ex in examples[\"input\"]]\n    outputs = [ex for ex in examples[\"output\"]]\n\n    model_inputs = tokenizer(inputs, max_length=512, truncation=True, padding=\"max_length\")\n    labels = tokenizer(outputs, max_length=256, truncation=True, padding=\"max_length\")\n\n    model_inputs[\"labels\"] = labels[\"input_ids\"]\n    return model_inputs\n\ntokenized_data = dataset.map(preprocess_function, batched=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from huggingface_hub import notebook_login\n\nnotebook_login()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import TrainingArguments\n\ntraining_args = TrainingArguments(\n    output_dir=\"./out_dir\",\n    run_name=\"OBSRVR_run1\",\n    eval_strategy=\"steps\",\n    save_strategy=\"steps\",\n    eval_steps=500,\n    save_steps=500,\n    logging_steps=500,\n    learning_rate=2e-5, # you can change here\n    warmup_steps=500,\n    logging_first_step=True,\n    per_device_train_batch_size=4,  # you can change here\n    per_device_eval_batch_size=4,\n    num_train_epochs =5,   # you can change here\n    weight_decay=0.01,  # you can change here\n    logging_dir=\"./logs\",\n    save_total_limit=2,\n    load_best_model_at_end=True,\n    push_to_hub=False,  # set True to save at your huggingface account\n    hub_model_id=\"username/model_name\", #username/model_name\n    hub_strategy=\"checkpoint\",\n    metric_for_best_model=\"loss\",\n    resume_from_checkpoint=False # set to True to continue training if stopped before\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import Trainer, DataCollatorForSeq2Seq\n\ndata_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_data[\"train\"],\n    eval_dataset=tokenized_data[\"validation\"],\n    data_collator=data_collator\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import wandb\n\nwandb.init(project=\"OBSRVR\", name=\"OBSRVR_run1\", config={}, mode=\"offline\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer.train()  # add : resume_from_checkpoint=\"./out_dir/last-checkpoint\" to continue training if stopped\n#replace ./out_dir with what you chose above in model params","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}